# PEP Парсер

Данный проект представляет собой веб-скрапер на языке Python, 
который парсит документы PEP (Python Enhancement Proposal) с веб-сайта 
Python PEPs (*https://peps.python.org/*) и сохраняет собранную информацию в CSV-файлы. 
Он извлекает номер PEP, название и статус, и генерирует два выходных 
файла: один содержит список всех PEP, а другой предоставляет сводку по статусам PEP.

## Технологии
- Python 3.6+
- Scrapy

## Установка
1. Клонируйте репозиторий
```bash
git clone https://github.com/Ezereul/scrapy_parser_pep.git
```
2. В директории проекта разверните виртуальное окружение и установите зависимости
```bash
python -m venv venv
pip install -r requirements.txt
```

## Использование
Запустите парсер при помощи следующей команды
```bash
scrapy crawl pep
```

## Примеры использования

После запуска парсера вы можете найти выходные файлы в директории `results/`.
Вот пример содержимого каждого из CSV-файлов:

`pep_<временная_метка>.csv`:

| Номер | Название | Статус |
|-------|----------|--------|
| PEP 8 | Style Guide for Python Code | Active |

`status_summary_<временная_метка>.csv`:

| Статус | Количество |
|--------|------------|
| Active | 250 |

Вместо `<временная_метка>` подставляется время создания файла в формате `YYYY-MM-DD_hh-mm-ss`.

## Об авторе

Если у вас есть вопросы или предложения,
свяжитесь со мной по электронной почте на isaev_0602@mail.ru или через 
мой профиль на GitHub по адресу https://github.com/Ezereul.